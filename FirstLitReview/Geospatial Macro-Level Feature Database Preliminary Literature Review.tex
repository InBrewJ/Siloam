\documentclass[a4paper]{article}

\usepackage{pdfpages}
\usepackage{scrextend}
\setlength\parindent{12pt}
\usepackage{graphicx}
\usepackage{float}
\usepackage{relsize}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{textcomp}
\usepackage{hyperref}

\title{MSc Project: Geospatial Macro-Level Feature Database, Preliminary Literature Review}
\author{Sandra Garcia Lamadrid, Jason Brewer}
\date{}

\begin{document}

\maketitle

\section{Micro-navigation}

Everyday, those with visual impairments leave their homes and face countless obstacles that can represent a risk to them both in the open world and enclosed public spaces. For many visually impaired people, autonomous displacement is a problem and some, in fact, avoid it at all costs. \parGiven technological advances, location can be obtained with certain precision through the use of GPS (Global Positioning System) in open places where signal strength to e.g. smartphones is strong enough. Although thanks to the GPS finding coordinates on street level is much simpler, once we are inside a building an issue arises: you cannot use the signal from the satellites. \parAs part of the objective of this project, we seek to develop a system that helps these people to move with a certain degree of confidence within a closed space, without the need to have a number of sensors installed in the immediate vicinity. It is very important to develop a tool that provides information on the relevant elements of the physical environment for the visually impaired as well as corridors, doors, stairs, etc. This type of solution is known as a micro-navigation system \cite{bradley_experimental_2005} which must detect the position or route of a user, and the positioning of all elements in the environment. \par\subsection{An alternative for GPS system for indoor navigation}IndoorAtlas, based in Finland and developed by the University of Oulu, is a technology, designed for mobile software developers to use in other applications, a new approach within the growing market for indoor tracking systems. ``Many animals use anomalies in the Earth's magnetic field for self-positioning. IndoorAtlas enables the same for humans indoors with just a mobile device equipped with a magnetometer at hand'' \cite{noauthor_indooratlas_nodate}. \parA standout feature of the system is that it is based solely on software. It is not necessary to install any extra component as long a smartphone with a magnetometer is available. For the service to work, all you have to do is create a map of the building and then go through all its dependencies with a mobile programmed with the SDK supplied by the company that is responsible for measuring the magnetic field patterns. Then you can use this information as a developer for specific purposes. \parAnother technology currently used is a new wireless technology called Ultra-Wideband (UWB). This tool offers several advantages over other wireless technologies, including its resistance to narrowband interference and its robustness in complex indoor multi-path environments \cite{riehle_indoor_2008}.\parAn alternative was developed by Sonnenblick \cite{sonnenblick1998indoor} using infrared LEDs, which should be located strategically in the environment to act as guides for the disabled. The signal emitted by the LEDs must be interpreted by a special device and transformed for use by the user. However, once again it is necessary to have the necessary infrastructure in the environment and install the relevant devices, which raises costs and therefore reduces economic accessibility.\parAs mentioned, currently there are multiple tools for interior support for people with visual disabilities such as sensors, electronic batons, RFID tags \cite{schmitz_acquisition_2011}, and even use of a head mounted Kinect sensor as in the case of NAVI \cite{zollner_navi_2011}. However, our project seeks to make the most of the ubiquity of smartphones. \par
An alternative to the magnetic approach is the system proposed by Serrão et al. \cite{serrao_navigation_2014}. This uses the SURF algorithm for feature detection as developed by Chris Evans \cite{evans_opensurf_2015} in conjunction with GIS data for a given indoor environment. 
\subsection{VPS}
A new technology, ``VPS'' (Visual Positioning System) was recently announced at Google's 2017 I/O conference that aims to bridge the gulf between the well known Street View technology and the interiors of buildings. VPS uses Google's own Tango \cite{noauthor_tango_nodate} system to eliminate the need for GPS satellite signals.\par 
Since Tango enabled devices are capable of depth perception they result in two opportunities in developing applications for the visually impaired user. Firstly, they allow real time tracking of moving objects and/or obstacles in a given scene, giving up to date information of the user's surroundings. If a given application was in communication with an online database that was used for mapping and wayfinding purposes, the data gathered from such a device could be used to update the database in real time, acting in a similar fashion to a traffic monitor on an automotive satellite navigation system. Secondly, coupled with a machine learning algorithm for feature classification and detection, a VPS-esque system would negate the need for traditional photogrammetry techniques. \par
Tango devices, at their core, include so called RGB-D sensors, meaning that depth information and RGB texture data can be captured simultaneously to create 3D models that can be compared to those in a pre-populated database. Song and Xiao \cite{song_sliding_2014} have made progress in high performance 3D object detection. These features help to overcome the limitations of indoor positioning infrastructure as discussed by Schmitz et al. \cite{schmitz_acquisition_2011}. \par       

\section{Macro-navigation}

Jafri and Khan \cite{jafri_obstacle_2016} state that the detection of drop-offs are a factor in the confidence of visually impaired users navigating unknown outdoor spaces. A current application similar to their research is realised in Cydalion \cite{noauthor_cydalion._nodate}, but this implementation fails to address the real needs of the visually impaired user. Research by Quinones et al. \cite{quinones_supporting_2011} highlights the paramount need for both accurate re-routing if an impedance is encountered e.g. by ongoing pavement maintenance and re-orientation to a planned route once the obstruction has been circumnavigated. Also highlighted was the need for accurate weather information as this can greatly change the feel of the waypoints that visually impaired users employ to orientate themselves. Furthermore, the study suggests that technologies applied to this area should supply information about landmarks that could be viable candidates to build a solid mental map of a route. Other senses apart from the touch of a white cane and hearing are active at all times: some candidates reported that they used the smell of e.g. a coffee shop to orientate themselves. \par
For this project, then, the task at hand is to map the outdoor area of the University of Liverpool campus and accurately define a set of possible waypoints upon which visually impaired users can base their exploration. Much of the mapping available on streets accessible by automobiles is covered by the ever popular Street View, but some of the pedestrianised areas of the campus can only be added to the Street View database by manually uploading panoramic ``photospheres'' taken with any reasonable modern smartphone. Once in the system, specific images can be accessed via the Google Street View Image API \cite{noauthor_google_nodate}. Features could then be learned from these images and used to populate a geocoded database of macro-level features using a variety of traditional machine learning techniques \cite{duro_comparison_2012,ciregan_multi-column_2012,chapelle_support_1999} . \par
A promising and community driven competitor to Google Maps and Street View (although not directly) is OpenStreetMap (OSM) \cite{noauthor_openstreetmap_nodate}. One interesting feature about OSM is that is includes the GPS locations of many individual trees - a common waypoint used by the visually impaired. \par 
At present there is no established way to link the mapping data from OSM to photospheres as with Street View, but the platform does implement a RESTful API that could be used to download portions of map data corresponding to the University of Liverpool campus. This GIS data allied with the object data recognition capabilities of a Tango device taken outdoors has the potential to yield favourable results. A Tango C/C++ API is available \cite{noauthor_getting_nodate}. \par
Schmitz et al. \cite{schmitz_acquisition_2011} also highlight the need for up to date textual information e.g. at bus stops and train stations. These needs are currently being developed by the Ariane Project \cite{noauthor_ariane_nodate}. \par
Whilst these various areas of research all aim to tackle the same problem, none succeed without sacrificing the key needs of the visually impaired user; that is the need to define meaningful waypoints for future route planning whilst being able to navigate in an area that is not retrofitted with some sort of sensor/emitter infrastructure. 

\newpage

\bibliographystyle{IEEEtran}
\bibliography{References}

\end{document}