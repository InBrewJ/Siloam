
@article{chapelle_support_1999,
	title = {Support vector machines for histogram-based image classification},
	volume = {10},
	issn = {1045-9227},
	doi = {10.1109/72.788646},
	abstract = {Traditional classification approaches generalize poorly on image classification tasks, because of the high dimensionality of the feature space. This paper shows that support vector machines (SVM) can generalize well on difficult image classification problems where the only features are high dimensional histograms. Heavy-tailed RBF kernels of the form K(x, y)=e-ρΣi{\textbar}xia-yia{\textbar}b with a ⩽1 and b⩽2 are evaluated on the classification of images extracted from the Corel stock photo collection and shown to far outperform traditional polynomial or Gaussian radial basis function (RBF) kernels. Moreover, we observed that a simple remapping of the input xi→xia improves the performance of linear SVM to such an extend that it makes them, for this problem, a valid alternative to RBF kernels},
	number = {5},
	journal = {IEEE Transactions on Neural Networks},
	author = {Chapelle, O. and Haffner, P. and Vapnik, V. N.},
	month = sep,
	year = {1999},
	keywords = {Classification tree analysis, Corel stock photo collection, feature space dimensionality, heavy-tailed RBF kernels, high-dimensional histograms, histogram-based image classification, Histograms, image classification, Image databases, Image recognition, Kernel, learning (artificial intelligence), linear SVM, Polynomials, radial basis function networks, remapping, Support vector machine classification, support vector machines, Web pages},
	pages = {1055--1064},
	file = {IEEE Xplore Abstract Record:/Users/LordNelson/Library/Application Support/Zotero/Profiles/vn3m5a3z.default/zotero/storage/C93BAXGJ/788646.html:text/html}
}

@inproceedings{ciregan_multi-column_2012,
	title = {Multi-column deep neural networks for image classification},
	doi = {10.1109/CVPR.2012.6248110},
	abstract = {Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible, wide and deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.},
	booktitle = {2012 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Ciregan, D. and Meier, U. and Schmidhuber, J.},
	month = jun,
	year = {2012},
	keywords = {artificial neural network architectures, Benchmark testing, Computer architecture, computer vision, convolutional winner-take-all neurons, Error analysis, fast training, graphics cards, Graphics processing unit, graphics processing units, handwritten character recognition, handwritten digits recognition, human performance, image classification, Image recognition, learning (artificial intelligence), machine learning, MNIST handwriting benchmark, multicolumn deep neural networks, neural nets, Neurons, retina, sparsely connected neural layers, traffic sign recognition benchmark, traffic signs, Training, visual cortex},
	pages = {3642--3649},
	file = {IEEE Xplore Abstract Record:/Users/LordNelson/Library/Application Support/Zotero/Profiles/vn3m5a3z.default/zotero/storage/C7UP7AGI/6248110.html:text/html}
}

@article{duro_comparison_2012,
	title = {A comparison of pixel-based and object-based image analysis with selected machine learning algorithms for the classification of agricultural landscapes using {SPOT}-5 {HRG} imagery},
	volume = {118},
	issn = {0034-4257},
	url = {http://www.sciencedirect.com/science/article/pii/S0034425711004172},
	doi = {10.1016/j.rse.2011.11.020},
	abstract = {Pixel-based and object-based image analysis approaches for classifying broad land cover classes over agricultural landscapes are compared using three supervised machine learning algorithms: decision tree (DT), random forest (RF), and the support vector machine (SVM). Overall classification accuracies between pixel-based and object-based classifications were not statistically significant (p{\textgreater}0.05) when the same machine learning algorithms were applied. Using object-based image analysis, there was a statistically significant difference in classification accuracy between maps produced using the DT algorithm compared to maps produced using either RF (p=0.0116) or SVM algorithms (p=0.0067). Using pixel-based image analysis, there was no statistically significant difference (p{\textgreater}0.05) between results produced using different classification algorithms. Classifications based on RF and SVM algorithms provided a more visually adequate depiction of wetland, riparian, and crop land cover types when compared to DT based classifications, using either object-based or pixel-based image analysis. In this study, pixel-based classifications utilized fewer variables (15 vs. 300), achieved similar classification accuracies, and required less time to produce than object-based classifications. Object-based classifications produced a visually appealing generalized appearance of land cover classes. Based exclusively on overall accuracy reports, there was no advantage to preferring one image analysis approach over another for the purposes of mapping broad land cover types in agricultural environments using medium spatial resolution earth observation imagery.},
	journal = {Remote Sensing of Environment},
	author = {Duro, Dennis C. and Franklin, Steven E. and Dubé, Monique G.},
	month = mar,
	year = {2012},
	keywords = {Comparison, Decision tree, Object-based, Random forest, Support vector machine},
	pages = {259--272},
	file = {ScienceDirect Snapshot:/Users/LordNelson/Library/Application Support/Zotero/Profiles/vn3m5a3z.default/zotero/storage/NR23EKKS/S0034425711004172.html:text/html}
}